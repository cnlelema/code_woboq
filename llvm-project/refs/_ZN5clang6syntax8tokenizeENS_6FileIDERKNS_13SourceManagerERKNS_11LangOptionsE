<dec f='llvm/clang/include/clang/Tooling/Syntax/Tokens.h' l='275' type='std::vector&lt;syntax::Token&gt; clang::syntax::tokenize(clang::FileID FID, const clang::SourceManager &amp; SM, const clang::LangOptions &amp; LO)'/>
<def f='llvm/clang/lib/Tooling/Syntax/Tokens.cpp' l='202' ll='227' type='std::vector&lt;syntax::Token&gt; clang::syntax::tokenize(clang::FileID FID, const clang::SourceManager &amp; SM, const clang::LangOptions &amp; LO)'/>
<use f='llvm/clang/lib/Tooling/Syntax/Tokens.cpp' l='366' u='c' c='_ZN5clang6syntax14TokenCollector7Builder18buildSpelledTokensEv'/>
<doc f='llvm/clang/include/clang/Tooling/Syntax/Tokens.h' l='267'>/// Lex the text buffer, corresponding to \p FID, in raw mode and record the
/// resulting spelled tokens. Does minimal post-processing on raw identifiers,
/// setting the appropriate token kind (instead of the raw_identifier reported
/// by lexer in raw mode). This is a very low-level function, most users should
/// prefer to use TokenCollector. Lexing in raw mode produces wildly different
/// results from what one might expect when running a C++ frontend, e.g.
/// preprocessor does not run at all.
/// The result will *not* have a &apos;eof&apos; token at the end.</doc>
<use f='llvm/clang/unittests/Tooling/Syntax/TokensTest.cpp' l='150' u='c' c='_ZN12_GLOBAL__N_118TokenCollectorTest8tokenizeEN4llvm9StringRefE'/>
